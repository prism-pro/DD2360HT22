{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K9bYwy7vndiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19361aff-85ce-4de3-e554-1e1665f987e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DD2360HT22' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/prism-pro/DD2360HT22.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir cufiles\n",
        "!cp -f DD2360HT22/hw_3/*.cu ./cufiles\n"
      ],
      "metadata": {
        "id": "AHqumw59BnRX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -I/usr/local/cuda-11/samples/common/inc ./cufiles/lab3_ex1.cu -o ex1"
      ],
      "metadata": {
        "id": "803poWJrCsvI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./ex1 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7oRhuZDDz_3",
        "outputId": "7301c7d9-b12d-4336-d938-71effe0de5de"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 131070\n",
            "Time comsuption of copying memory of 131070 data to the GPU is 0.000559 s \n",
            " Time comsuption of computing  131070 data in the GPU is 0.000071 s \n",
            " Time comsuption of copying memory of 131070 data to the host is 0.000744 s \n",
            " the results are equal."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda-11/bin/nv-nsight-cu-cli ./ex1 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIsVGWCSPMu8",
        "outputId": "fb3a4c96-cff5-45a1-f846-b33d17b52ca4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 131070\n",
            "==PROF== Connected to process 1489 (/content/ex1)\n",
            "==PROF== Profiling \"vecAdd\" - 1: 0%....50%....100% - 8 passes\n",
            "Time comsuption of copying memory to the GPU is 0.000612 the results are equal.==PROF== Disconnected from process 1489\n",
            "[1489] ex1@127.0.0.1\n",
            "  vecAdd(double*, double*, double*, int), 2022-Dec-15 15:25:45, Context 1, Stream 7\n",
            "    Section: GPU Speed Of Light\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    DRAM Frequency                                                           cycle/nsecond                           5.03\n",
            "    SM Frequency                                                             cycle/usecond                         587.82\n",
            "    Elapsed Cycles                                                                   cycle                          6,645\n",
            "    Memory [%]                                                                           %                          62.81\n",
            "    SOL DRAM                                                                             %                          62.81\n",
            "    Duration                                                                       usecond                          11.30\n",
            "    SOL L1/TEX Cache                                                                     %                          32.00\n",
            "    SOL L2 Cache                                                                         %                          32.92\n",
            "    SM Active Cycles                                                                 cycle                       5,120.73\n",
            "    SM [%]                                                                               %                          24.67\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      \n",
            "          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           \n",
            "          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  \n",
            "          access (kernel fusion) or whether there are values you can (re)compute.                                       \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Size                                                                                                        256\n",
            "    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n",
            "    Grid Size                                                                                                         512\n",
            "    Registers Per Thread                                                   register/thread                             16\n",
            "    Shared Memory Configuration Size                                                 Kbyte                          32.77\n",
            "    Driver Shared Memory Per Block                                              byte/block                              0\n",
            "    Dynamic Shared Memory Per Block                                             byte/block                              0\n",
            "    Static Shared Memory Per Block                                              byte/block                              0\n",
            "    Threads                                                                         thread                        131,072\n",
            "    Waves Per SM                                                                                                     3.20\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n",
            "          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n",
            "          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 32 thread blocks.   \n",
            "          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n",
            "          up to 25.0% of the total kernel runtime with a lower occupancy of 22.2%. Try launching a grid with no         \n",
            "          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n",
            "          a grid.                                                                                                       \n",
            "\n",
            "    Section: Occupancy\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "    Block Limit SM                                                                   block                             16\n",
            "    Block Limit Registers                                                            block                             16\n",
            "    Block Limit Shared Mem                                                           block                             16\n",
            "    Block Limit Warps                                                                block                              4\n",
            "    Theoretical Active Warps per SM                                                   warp                             32\n",
            "    Theoretical Occupancy                                                                %                            100\n",
            "    Achieved Occupancy                                                                   %                          77.81\n",
            "    Achieved Active Warps Per SM                                                      warp                          24.90\n",
            "    ---------------------------------------------------------------------- --------------- ------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess \n",
        "import re"
      ],
      "metadata": {
        "id": "vB-61jLfcrtE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = subprocess.run(f'./ex1 131070', shell=True, capture_output=True)\n",
        "txt = p.stdout.decode('utf-8')\n",
        "\n",
        "print(re.findall(\"\\d+\\.?\\d*\", txt) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Z8yFIdc5Eg",
        "outputId": "89dee20d-1fa0-4856-c505-f60b7322cbf0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['131070', '131070', '0.000598', '131070', '0.000108', '131070', '0.000811']\n"
          ]
        }
      ]
    }
  ]
}